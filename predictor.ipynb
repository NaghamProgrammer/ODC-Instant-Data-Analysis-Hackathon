{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1) Real Sum Predictor"
      ],
      "metadata": {
        "id": "l1KJvx5D6asX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8DmTb3i3JW-",
        "outputId": "92f44ec8-a78a-4eb6-e046-9884e23ad6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1762\n",
            "[LightGBM] [Info] Number of data points in the train set: 15955, number of used features: 93\n",
            "[LightGBM] [Info] Start training from score 5.267918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 43.64\n",
            "RMSE: 75.08\n",
            "Median Error: 25.00\n",
            "R²: 0.770\n",
            "Tolerance Accuracy (±10%): 36.63%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "\n",
        "#Load and preprocessing\n",
        "df = pd.read_csv(\"final_df2.csv\")\n",
        "df = df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "#Remove extreme outliers\n",
        "upper_limit = df[\"realSum\"].quantile(0.99)  # keep 99% of data\n",
        "df = df[df[\"realSum\"] <= upper_limit]\n",
        "\n",
        "\n",
        "#Target and features\n",
        "X = df.drop(columns=[\"realSum\"])\n",
        "y = np.log1p(df[\"realSum\"])  # log transform price\n",
        "\n",
        "\n",
        "#Feature groups\n",
        "categorical_features = [\n",
        "    \"room_type\",\n",
        "    \"day_type\",\n",
        "    \"city\",\n",
        "    \"country\"\n",
        "]\n",
        "\n",
        "boolean_features = [\n",
        "    \"room_shared\",\n",
        "    \"room_private\",\n",
        "    \"host_is_superhost\"\n",
        "]\n",
        "\n",
        "numeric_features = [\n",
        "    \"person_capacity\",\n",
        "    \"multi\",\n",
        "    \"biz\",\n",
        "    \"cleanliness_rating\",\n",
        "    \"guest_satisfaction_overall\",\n",
        "    \"bedrooms\",\n",
        "    \"dist\",\n",
        "    \"metro_dist\",\n",
        "    \"attr_index_norm\",\n",
        "    \"rest_index_norm\",\n",
        "    \"lat\",\n",
        "    \"lng\"\n",
        "]\n",
        "\n",
        "\n",
        "# more Preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "        (\"num\", \"passthrough\", numeric_features),\n",
        "        (\"bool\", \"passthrough\", boolean_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# the model\n",
        "model = LGBMRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    num_leaves=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", model)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "#Train / Test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "#Training\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#Evaluation\n",
        "\n",
        "y_pred_log = pipeline.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log)   # revert log\n",
        "y_true = np.expm1(y_test)\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "median_error = np.median(np.abs(y_true - y_pred))\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"Median Error: {median_error:.2f}\")\n",
        "print(f\"R²: {r2:.3f}\")\n",
        "\n",
        "# tolerance accuracy (±10%)\n",
        "tolerance = 0.10\n",
        "tolerance_acc = np.mean(np.abs(y_pred - y_true) / y_true < tolerance)\n",
        "print(f\"Tolerance Accuracy (±10%): {tolerance_acc:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.DataFrame([{\n",
        "    \"room_type\": \"Entire home/apt\",\n",
        "    \"room_shared\": False,\n",
        "    \"room_private\": False,\n",
        "    \"person_capacity\": 4,\n",
        "    \"host_is_superhost\": True,\n",
        "    \"multi\": 0,\n",
        "    \"biz\": 1,\n",
        "    \"cleanliness_rating\": 9.5,\n",
        "    \"guest_satisfaction_overall\": 95,\n",
        "    \"bedrooms\": 2,\n",
        "    \"dist\": 2.1,\n",
        "    \"metro_dist\": 0.4,\n",
        "    \"attr_index_norm\": 1.2,\n",
        "    \"rest_index_norm\": 1.1,\n",
        "    \"lat\": 48.8566,\n",
        "    \"lng\": 2.3522,\n",
        "    \"day_type\": \"weekend\",\n",
        "    \"city\": \"Paris\",\n",
        "    \"country\": \"France\"\n",
        "}])\n",
        "\n",
        "log_price = pipeline.predict(sample)[0]\n",
        "price = np.expm1(log_price)\n",
        "\n",
        "print(f\"Predicted price: {price:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MZPcek04GAu",
        "outputId": "77a4e366-4095-44b9-c4d7-c92093a85924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price: 292.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2) City Predictor"
      ],
      "metadata": {
        "id": "7zxRcItx6hS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Load data and preprocess\n",
        "\n",
        "df = pd.read_csv(\"final_df2.csv\")\n",
        "df = df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "\n",
        "#keep top 20 cities for speed\n",
        "\n",
        "top_cities = df['city'].value_counts().head(20).index\n",
        "df = df[df['city'].isin(top_cities)]\n",
        "\n",
        "\n",
        "#Features and target\n",
        "\n",
        "X = df[['realSum', 'person_capacity', 'bedrooms',\n",
        "        'room_shared', 'room_private', 'host_is_superhost']]\n",
        "\n",
        "# Convert booleans to int (use safe way)\n",
        "X.loc[:, ['room_shared','room_private','host_is_superhost']] = X[['room_shared','room_private','host_is_superhost']].astype(int)\n",
        "\n",
        "y = df['city']\n",
        "\n",
        "\n",
        "# Encode target\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "num_classes = len(le.classes_)\n",
        "y_categorical = to_categorical(y_encoded, num_classes=num_classes)\n",
        "\n",
        "\n",
        "# Train/test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "\n",
        "# Scale numeric features\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# neural network\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#Training loop\n",
        "history = model.fit(X_train_scaled, y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.1,\n",
        "                    verbose=2)\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "y_pred_prob = model.predict(X_test_scaled)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(f\"\\nAccuracy: {acc:.3f}\")\n",
        "print(f\"Weighted F1: {f1:.3f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "\n",
        "# Top-5 accuracy\n",
        "\n",
        "top_k = 5\n",
        "top_k_preds = np.argsort(y_pred_prob, axis=1)[:, -top_k:]\n",
        "top_k_correct = [y_true[i] in top_k_preds[i] for i in range(len(y_true))]\n",
        "top_k_accuracy = np.mean(top_k_correct)\n",
        "print(f\"Top-{top_k} accuracy: {top_k_accuracy:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bTEWw4y-mRU",
        "outputId": "200244f8-9db3-4ba4-b318-7f99800629f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3210352026.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 0 0 ... 0 0 0]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  X.loc[:, ['room_shared','room_private','host_is_superhost']] = X[['room_shared','room_private','host_is_superhost']].astype(int)\n",
            "/tmp/ipython-input-3210352026.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1 1 1 ... 0 1 1]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  X.loc[:, ['room_shared','room_private','host_is_superhost']] = X[['room_shared','room_private','host_is_superhost']].astype(int)\n",
            "/tmp/ipython-input-3210352026.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 0 1 ... 0 0 1]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  X.loc[:, ['room_shared','room_private','host_is_superhost']] = X[['room_shared','room_private','host_is_superhost']].astype(int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "388/388 - 4s - 10ms/step - accuracy: 0.2921 - loss: 2.3470 - val_accuracy: 0.3365 - val_loss: 2.0414\n",
            "Epoch 2/30\n",
            "388/388 - 1s - 3ms/step - accuracy: 0.3306 - loss: 2.0658 - val_accuracy: 0.3586 - val_loss: 1.9694\n",
            "Epoch 3/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3420 - loss: 2.0073 - val_accuracy: 0.3623 - val_loss: 1.9239\n",
            "Epoch 4/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3431 - loss: 1.9852 - val_accuracy: 0.3583 - val_loss: 1.9147\n",
            "Epoch 5/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3473 - loss: 1.9714 - val_accuracy: 0.3637 - val_loss: 1.9054\n",
            "Epoch 6/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3499 - loss: 1.9615 - val_accuracy: 0.3641 - val_loss: 1.9055\n",
            "Epoch 7/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3467 - loss: 1.9556 - val_accuracy: 0.3626 - val_loss: 1.8975\n",
            "Epoch 8/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3507 - loss: 1.9479 - val_accuracy: 0.3662 - val_loss: 1.8969\n",
            "Epoch 9/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3529 - loss: 1.9442 - val_accuracy: 0.3673 - val_loss: 1.8897\n",
            "Epoch 10/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3537 - loss: 1.9393 - val_accuracy: 0.3655 - val_loss: 1.8921\n",
            "Epoch 11/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3529 - loss: 1.9359 - val_accuracy: 0.3637 - val_loss: 1.8842\n",
            "Epoch 12/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3535 - loss: 1.9370 - val_accuracy: 0.3673 - val_loss: 1.8923\n",
            "Epoch 13/30\n",
            "388/388 - 1s - 3ms/step - accuracy: 0.3576 - loss: 1.9314 - val_accuracy: 0.3666 - val_loss: 1.8877\n",
            "Epoch 14/30\n",
            "388/388 - 2s - 4ms/step - accuracy: 0.3558 - loss: 1.9302 - val_accuracy: 0.3688 - val_loss: 1.8840\n",
            "Epoch 15/30\n",
            "388/388 - 2s - 5ms/step - accuracy: 0.3532 - loss: 1.9285 - val_accuracy: 0.3659 - val_loss: 1.8909\n",
            "Epoch 16/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3558 - loss: 1.9269 - val_accuracy: 0.3619 - val_loss: 1.8871\n",
            "Epoch 17/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3569 - loss: 1.9254 - val_accuracy: 0.3623 - val_loss: 1.8848\n",
            "Epoch 18/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3544 - loss: 1.9225 - val_accuracy: 0.3695 - val_loss: 1.8883\n",
            "Epoch 19/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3582 - loss: 1.9201 - val_accuracy: 0.3648 - val_loss: 1.8837\n",
            "Epoch 20/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3589 - loss: 1.9163 - val_accuracy: 0.3648 - val_loss: 1.8868\n",
            "Epoch 21/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3561 - loss: 1.9191 - val_accuracy: 0.3597 - val_loss: 1.8768\n",
            "Epoch 22/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3578 - loss: 1.9171 - val_accuracy: 0.3604 - val_loss: 1.8841\n",
            "Epoch 23/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3580 - loss: 1.9170 - val_accuracy: 0.3623 - val_loss: 1.8853\n",
            "Epoch 24/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3566 - loss: 1.9126 - val_accuracy: 0.3670 - val_loss: 1.8777\n",
            "Epoch 25/30\n",
            "388/388 - 1s - 3ms/step - accuracy: 0.3589 - loss: 1.9100 - val_accuracy: 0.3652 - val_loss: 1.8769\n",
            "Epoch 26/30\n",
            "388/388 - 1s - 3ms/step - accuracy: 0.3585 - loss: 1.9124 - val_accuracy: 0.3648 - val_loss: 1.8821\n",
            "Epoch 27/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3573 - loss: 1.9130 - val_accuracy: 0.3684 - val_loss: 1.8804\n",
            "Epoch 28/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3579 - loss: 1.9112 - val_accuracy: 0.3652 - val_loss: 1.8781\n",
            "Epoch 29/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3594 - loss: 1.9081 - val_accuracy: 0.3666 - val_loss: 1.8839\n",
            "Epoch 30/30\n",
            "388/388 - 1s - 2ms/step - accuracy: 0.3589 - loss: 1.9086 - val_accuracy: 0.3655 - val_loss: 1.8773\n",
            "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\n",
            "Accuracy: 0.362\n",
            "Weighted F1: 0.276\n",
            "Confusion Matrix:\n",
            "[[ 250    0    0    0    0    0    0    2    0    0    0    0    3    3\n",
            "    39    0   11    0    0    0]\n",
            " [   8   66    0    0    0    8    0    4    0    0  109    0   32    0\n",
            "     9    0  212    0   10    0]\n",
            " [  34    0    0    2    0    0    0    4    0    0    0    0   13    1\n",
            "    62    0   36    0    0    0]\n",
            " [  40    0    0    2    0    0    0    3    0    0    0    0   14    1\n",
            "    31    0  145    0    0    0]\n",
            " [   1    8    0    0    0    5    0    0    0    0    8    0   12    0\n",
            "     4    0   63    0    2    0]\n",
            " [   2   33    0    0    0   12    0    0    0    0   11    0   15    0\n",
            "     6    0  133    0   13    0]\n",
            " [   1   38    0    0    0    7    0    0    0    0   18    0    3    0\n",
            "     1    0   73    0    1    0]\n",
            " [  32    0    0    0    0    0    0    7    0    0    0    0    6    0\n",
            "    20    0  103    0    0    0]\n",
            " [   0   24    0    0    0    1    0    0    0    0   25    0    2    0\n",
            "     0    0   45    0    2    0]\n",
            " [  27    0    0    0    0    0    0    6    0    0    0    0   11    1\n",
            "    48    0   30    0    0    0]\n",
            " [   0   34    0    0    0    2    0    0    0    0  154    0    0    0\n",
            "     1    0   79    0    0    0]\n",
            " [   7    0    0    0    0    0    0    0    0    0    0    0   29    2\n",
            "    15    0   36    0    3    0]\n",
            " [   7    0    0    2    0    1    0    2    0    0    0    0  275    0\n",
            "    44    0  592    0   20    0]\n",
            " [  57    0    0    0    0    0    0    6    0    0    0    0    1    8\n",
            "    29    0   13    0    0    0]\n",
            " [ 112    0    0    1    0    0    0    7    0    0    0    0   87    0\n",
            "   274    0   63    0    0    0]\n",
            " [  18    0    0    0    0    0    0    4    0    0    0    0    9    1\n",
            "    17    0   76    0    0    0]\n",
            " [  41   37    0    1    0   11    0    5    0    0   17    0  195    0\n",
            "    45    0 1424    0   18    0]\n",
            " [  34    1    0    1    0    0    0    3    0    0    0    0   52    0\n",
            "    59    0   48    0   10    0]\n",
            " [  16    5    0    1    0    5    0    1    0    0    1    0  133    0\n",
            "    39    0  422    0   23    0]\n",
            " [   2   22    0    0    0    0    0    0    0    0   50    0    6    0\n",
            "     1    0   56    0    0    0]]\n",
            "Top-5 accuracy: 0.831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.DataFrame([{\n",
        "    'realSum': 120,\n",
        "    'person_capacity': 2,\n",
        "    'bedrooms': 1,\n",
        "    'room_shared': 0,\n",
        "    'room_private': 0,\n",
        "    'host_is_superhost': 1\n",
        "}])\n",
        "\n",
        "sample_scaled = scaler.transform(sample)\n",
        "sample_pred_prob = model.predict(sample_scaled)[0]\n",
        "\n",
        "# Get top 5 city indices\n",
        "top_5_indices = np.argsort(sample_pred_prob)[-5:][::-1]  # descending order\n",
        "top_5_cities = le.inverse_transform(top_5_indices)\n",
        "top_5_probs = sample_pred_prob[top_5_indices]\n",
        "\n",
        "print(\"\\nTop 5 predicted cities for sample listing:\")\n",
        "for city, prob in zip(top_5_cities, top_5_probs):\n",
        "    print(f\"{city}: {prob:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0qvLL4t_5UT",
        "outputId": "a9a5570a-a2e2-4688-dd95-a32ef1916e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "Top 5 predicted cities for sample listing:\n",
            "Athens: 0.221\n",
            "Kipseli: 0.204\n",
            "Budapest VI. keruelet: 0.141\n",
            "Vyronas: 0.122\n",
            "Rome: 0.098\n"
          ]
        }
      ]
    }
  ]
}